#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
# sbgen â€” Sing-box / Xray configuration generator
# -----------------------------------------------
# Author: Ivan Tarasov
# Year: 2025
# License: MIT

import sys
import os
import yaml
import json
import re
import argparse
from typing import Any, Dict, List, Optional, Set

DEBUG = False

def debug_print(msg: str):
    if DEBUG:
        print(f">> {msg}", file=sys.stderr)

# ---------- input normalization ----------
def norm_list(x):
    if x is None:
        return []
    if isinstance(x, list):
        return x
    return [x]

def norm_bool(x, default=True):
    if x is None:
        return bool(default)
    return bool(x)

# ---------- patterns loader ----------
def _strip_inline_comment(line: str) -> str:
    out = []
    escaped = False
    for ch in line:
        if ch == '#' and not escaped:
            break
        if ch == '\\' and not escaped:
            escaped = True
        else:
            out.append(ch)
            escaped = False
    return "".join(out).strip()

def load_patterns_from_file(file_path: str) -> List[str]:
    pats: List[str] = []
    with open(file_path, "r", encoding="utf-8") as f:
        for ln, line in enumerate(f, 1):
            raw = line.strip()
            if not raw or raw.startswith("#"):
                continue
            cl = _strip_inline_comment(line).strip()
            if cl:
                pats.append(cl)
            else:
                debug_print(f"{file_path}:{ln} comment only")
    return pats

# ---------- include path resolution ----------
def resolve_include_path(include: str, item_base: Optional[str], tid_base: Optional[str], cli_base: Optional[str]) -> Optional[str]:
    if os.path.isabs(include):
        return include if os.path.isfile(include) else None

    for base in [item_base, tid_base, cli_base, os.getcwd()]:
        if base:
            c = os.path.join(base, include)
            if os.path.isfile(c):
                return os.path.abspath(c)

    debug_print(f"Include not found: {include}")
    return None

def collect_included_patterns(includes_field, item_base, tid_base, cli_base):
    out: List[str] = []
    for inc in norm_list(includes_field):
        if not isinstance(inc, str):
            continue
        p = resolve_include_path(inc, item_base, tid_base, cli_base)
        if not p:
            continue
        try:
            pats = load_patterns_from_file(p)
            debug_print(f"Loaded {len(pats)} patterns from include '{p}'")
            out.extend(pats)
        except Exception as e:
            debug_print(f"Failed to load include '{p}': {e}")
    return out

# ---------- classify patterns ----------
_WILD_ANY_LABEL = r"[^.]*"

def classify_pattern(p: Optional[str]):
    if not p:
        return None
    p = p.strip().lower()
    if not p:
        return None

    if p.startswith("*.") and len(p) > 2:
        return ("suffix", p[2:])
    if p.startswith(".") and len(p) > 1:
        return ("suffix", p[1:])
    if p.endswith(".*") and not p.startswith("*"):
        b = p[:-2]
        if b:
            rx = rf"^(.+\.)?{re.escape(b)}\.[^.]+$"
            return ("regex", rx)

    if "*" in p:
        rx = re.escape(p).replace(r"\*", _WILD_ANY_LABEL)
        return ("regex", rf"^{rx}$")

    return ("suffix", p)

# ---------- rules ----------
def generate_rules(inbound: str, patterns, outbound: str, xray_mode: bool):
    suf: List[str] = []
    reg: List[str] = []
    ss, sr = set(), set()

    for raw in norm_list(patterns):
        c = classify_pattern(raw)
        if not c:
            continue
        kind, val = c
        if kind == "suffix":
            val = val.lstrip(".")
            if val not in ss:
                ss.add(val)
                suf.append(val)
        else:
            if val not in sr:
                sr.add(val)
                reg.append(val)

    if not suf and not reg:
        return []

    if xray_mode:
        # Xray / V2Ray style
        r: Dict[str, Any] = {
            "type": "field",
            "inboundTag": [inbound],
            "outboundTag": outbound,
        }
        if suf:
            r["domainSuffix"] = suf
        if reg:
            r["domainRegex"] = reg
    else:
        # sing-box style
        r = {"inbound": inbound, "outbound": outbound}
        if suf:
            r["domain_suffix"] = suf
        if reg:
            r["domain_regex"] = reg

    return [r]

# ---------- sanitize trailing commas ----------
def _sanitize_trailing_commas(s: str) -> str:
    s = re.sub(r',\s*([\]}])', r'\1', s)
    s = re.sub(r'([\[{])\s*,', r'\1', s)
    s = re.sub(r',\s*,', ',', s)
    s = re.sub(r'\[\s*,\s*\]', '[]', s)
    s = re.sub(r'\{\s*,\s*\}', '{}', s)
    return s

# ---------- placeholders ----------
_PLACEH_RX = r'%%([^%:\s]+):([^%]+)%%'
_FINAL_TOKEN = "%%FINAL%%"

def _quote_unquoted_placeholders(text: str) -> str:
    text = re.sub(r'(?<!")(' + _PLACEH_RX + r')(?!")', r'"\1"', text)
    text = re.sub(r'(?<!")(' + re.escape(_FINAL_TOKEN) + r')(?!")', r'"\1"', text)
    return text

def _find_placeholders(node):
    f = []
    if isinstance(node, str):
        if re.fullmatch(_PLACEH_RX, node) or node == _FINAL_TOKEN:
            f.append(node)
    elif isinstance(node, list):
        for i in node:
            f += _find_placeholders(i)
    elif isinstance(node, dict):
        for v in node.values():
            f += _find_placeholders(v)
    return f

# ---------- outbounds detection ----------
def collect_available_out_tags(tpl_json, xray_mode: bool):
    tags = []
    seen = set()

    # Currently outbounds syntax is the same, just collect .tag
    arr = tpl_json.get("outbounds") or []
    for ob in arr:
        if isinstance(ob, dict):
            tag = ob.get("tag")
            if isinstance(tag, str) and tag not in seen:
                seen.add(tag)
                tags.append(tag)
    return tags

# ---------- pick FINAL ----------
def pick_final(config, tid: Optional[str], available: Set[str]):
    if not tid or tid not in config:
        return "direct"
    cfg = config[tid]
    if cfg.get("default_direct", True):
        return "direct"

    for lst in cfg.get("lists", []):
        outs = norm_list(lst.get("out"))
        for o in outs:
            if o in available:
                return o

    return "direct"

# ---------- AST replacement ----------
def ast_replace(node, rules_by_token, final_value):
    if isinstance(node, list):
        out = []
        for i in node:
            if isinstance(i, str) and i in rules_by_token:
                out.extend(rules_by_token[i])
            else:
                out.append(ast_replace(i, rules_by_token, final_value))
        return out

    if isinstance(node, dict):
        return {k: ast_replace(v, rules_by_token, final_value) for k,v in node.items()}

    if isinstance(node, str):
        if node == _FINAL_TOKEN and final_value is not None:
            return final_value
        return node

    return node

# ---------- main ----------
def main():
    global DEBUG

    ap = argparse.ArgumentParser(description="Generate sing-box/xray JSON from template + YAML config(s).")
    ap.add_argument("template", help="Path to JSON template with placeholders like %%tid:inbound%% (quoted or bare)")
    ap.add_argument("yamls", nargs="+", help="One or more YAML files with rules")
    ap.add_argument("-v","--verbose", action="store_true", help="Enable debug logging to stderr")
    ap.add_argument("-b","--base-dir", dest="cli_base_dir", default=None,
                    help="Optional base directory for resolving relative 'includes' (used after item/tid base dirs)")
    ap.add_argument("-a","--append", dest="append_rule",
                    help="Append raw fragment (string or JSON) into route/routing.rules[] before placeholder processing")
    ap.add_argument("-x","--xray", action="store_true", help="Xray mode")
    args = ap.parse_args()

    DEBUG = args.verbose

    if DEBUG:
        debug_print(f"Template: {args.template}")
        debug_print(f"YAML files: {args.yamls}")
        debug_print(f"CLI base_dir: {args.cli_base_dir or '(none)'}")
        debug_print(f"Mode: {'xray' if args.xray else 'sing-box'}")

    # load template
    if not os.path.isfile(args.template):
        print("Template not found", file=sys.stderr); sys.exit(1)

    txt = open(args.template,"r",encoding="utf-8").read()
    txt = _sanitize_trailing_commas(txt)
    txt = _quote_unquoted_placeholders(txt)

    try:
        tpl_json = json.loads(txt)
    except json.JSONDecodeError as e:
        print(f"JSON error: {e}", file=sys.stderr)
        sys.exit(1)

    # -------- append raw fragment into template BEFORE placeholder processing --------
    if args.append_rule:
        section = "routing" if args.xray else "route"
        if section not in tpl_json or "rules" not in tpl_json[section] or not isinstance(tpl_json[section]["rules"], list):
            print(f"Cannot append: section '{section}.rules' not found or not a list", file=sys.stderr)
        else:
            rules_list = tpl_json[section]["rules"]
            raw = args.append_rule
            try:
                parsed = json.loads(raw)
            except Exception:
                # treat as raw string (e.g. '%%russia:in-extra%%')
                rules_list.append(raw)
                debug_print(f"Appended raw string from -a into {section}.rules: {raw}")
            else:
                if isinstance(parsed, list):
                    rules_list.extend(parsed)
                    debug_print(f"Appended {len(parsed)} JSON rule(s) from -a into {section}.rules")
                else:
                    rules_list.append(parsed)
                    debug_print(f"Appended 1 JSON rule from -a into {section}.rules")

    available_tags_list = collect_available_out_tags(tpl_json, args.xray)
    available_tags = set(available_tags_list)

    debug_print(f"Available outbound tags: {available_tags_list}")

    # -------- YAML merge --------
    config: Dict[str, Dict[str, Any]] = {}
    tid_base: Dict[str, Optional[str]] = {}
    direct_bases: Dict[str, List[str]] = {}
    block_bases: Dict[str, List[str]] = {}

    for path in args.yamls:
        data = yaml.safe_load(open(path,"r",encoding="utf-8")) or {}
        base = os.path.dirname(os.path.abspath(path))

        debug_print(f"Loaded YAML: {os.path.basename(path)} (file_base={base})")

        for tid, sec in data.items():
            if tid not in config:
                config[tid] = {"lists":[], "direct":[], "blocked":[], "default_direct":True}
                tid_base[tid] = None
                direct_bases[tid] = []
                block_bases[tid] = []
                debug_print(f"New tid: {tid}")

            cfg = config[tid]

            if isinstance(sec, dict) and "base_dir" in sec and sec["base_dir"]:
                b = sec["base_dir"]
                tid_base[tid] = b if os.path.isabs(b) else os.path.abspath(os.path.join(base,b))
                debug_print(f"{tid}: base_dir set to {tid_base[tid]}")

            # lists
            for lst in sec.get("lists") or []:
                if isinstance(lst, dict):
                    obj = dict(lst)
                    obj["__base_dir"] = base
                    cfg["lists"].append(obj)

            # direct
            dsrc = sec.get("direct")
            if isinstance(dsrc, list):
                for it in dsrc:
                    if isinstance(it, dict):
                        o = dict(it); o["__base_dir"] = base; cfg["direct"].append(o)
                    else:
                        cfg["direct"].append(it)
                    direct_bases[tid].append(base)
            elif dsrc is not None:
                if isinstance(dsrc, dict):
                    o = dict(dsrc); o["__base_dir"] = base; cfg["direct"].append(o)
                else:
                    cfg["direct"].append(dsrc)
                direct_bases[tid].append(base)

            # blocked / block
            bsrc = sec.get("blocked") or sec.get("block")
            if isinstance(bsrc, list):
                for it in bsrc:
                    if isinstance(it, dict):
                        o = dict(it); o["__base_dir"] = base; cfg["blocked"].append(o)
                    else:
                        cfg["blocked"].append(it)
                    block_bases[tid].append(base)
            elif bsrc is not None:
                if isinstance(bsrc, dict):
                    o = dict(bsrc); o["__base_dir"] = base; cfg["blocked"].append(o)
                else:
                    cfg["blocked"].append(bsrc)
                block_bases[tid].append(base)

            cfg["default_direct"] = norm_bool(sec.get("default_direct"), default=cfg["default_direct"])

            debug_print(
                f"{tid}: lists={len(cfg['lists'])} direct={len(cfg['direct'])} "
                f"blocked={len(cfg['blocked'])} default_direct={cfg['default_direct']}"
            )

    # -------- find placeholders --------
    placeholders = _find_placeholders(tpl_json)
    debug_print(f"Placeholders in AST (order): {placeholders}")

    # -------- build rules --------
    rules_by_ph: Dict[str, List[Dict[str, Any]]] = {}

    for tok in placeholders:
        m = re.fullmatch(_PLACEH_RX, tok)
        if not m:
            continue
        tid, inbound = m.group(1), m.group(2)

        if tid not in config:
            rules_by_ph[tok] = []
            continue

        sec = config[tid]
        rules: List[Dict[str, Any]] = []

        # lists
        for lst in sec["lists"]:
            item_base = lst.get("__base_dir")
            pats: List[str] = []
            pats += collect_included_patterns(lst.get("includes"), item_base, tid_base.get(tid), args.cli_base_dir)
            pats += norm_list(lst.get("patterns"))
            outs = norm_list(lst.get("out"))
            for o in outs:
                if o in available_tags:
                    rules.extend(generate_rules(inbound, pats, o, args.xray))
                else:
                    debug_print(f"Skip list out='{o}' (not present in template outbounds)")

        # direct
        dp: List[str] = []
        src = sec["direct"]
        bases = direct_bases[tid]
        if isinstance(src, list):
            for it, ib in zip(src, bases):
                item = it
                if isinstance(item, dict):
                    ib = item.get("__base_dir", ib)
                    dp += collect_included_patterns(item.get("includes"),
                                                   ib, tid_base.get(tid), args.cli_base_dir)
                    dp += norm_list(item.get("patterns"))
                else:
                    dp.append(item)

        # blocked
        bp: List[str] = []
        src = sec["blocked"]
        bases = block_bases[tid]
        if isinstance(src, list):
            for it, ib in zip(src, bases):
                item = it
                if isinstance(item, dict):
                    ib = item.get("__base_dir", ib)
                    bp += collect_included_patterns(item.get("includes"),
                                                   ib, tid_base.get(tid), args.cli_base_dir)
                    bp += norm_list(item.get("patterns"))
                else:
                    bp.append(item)

        rules.extend(generate_rules(inbound, dp, "direct", args.xray))
        rules.extend(generate_rules(inbound, bp, "block", args.xray))

        rules_by_ph[tok] = rules

    # -------- FINAL --------
    final_value = None
    if _FINAL_TOKEN in placeholders:
        first_tid = next(iter(config.keys()), None)
        final_value = pick_final(config, first_tid, available_tags)
        debug_print(f"FINAL picked: {final_value} from tid={first_tid}")

    # -------- apply AST replace --------
    out_ast = ast_replace(tpl_json, rules_by_ph, final_value)

    print(json.dumps(out_ast, indent=2, ensure_ascii=False))

if __name__ == "__main__":
    main()

